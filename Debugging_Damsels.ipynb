{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tgi54njPieOahNdnOXdHbP6x6pKOW4am",
      "authorship_tag": "ABX9TyPXlPDT0A8pg/STJXb2QA+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saumyak2682/Debugging-Damsels/blob/main/Debugging_Damsels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def fetch_social_media_data(api_url, params):\n",
        "    response = requests.get(api_url, params=params)\n",
        "    return response.json()\n",
        "\n",
        "api_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
        "params = {\n",
        "    \"query\": \"#fashion\",\n",
        "    \"tweet.fields\": \"created_at,author_id\",\n",
        "    \"max_results\": 100\n",
        "}\n",
        "data = fetch_social_media_data(api_url, params)\n"
      ],
      "metadata": {
        "id": "EnTkMvZuKyhf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "customer_data = pd.read_csv('customer_data.csv')\n"
      ],
      "metadata": {
        "id": "qfRaPt7wK2CD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "survey_data = pd.read_csv('survey_data.csv')\n"
      ],
      "metadata": {
        "id": "ELdntW6sK6K1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df):\n",
        "    df.dropna(inplace=True)\n",
        "    # Additional cleaning steps\n",
        "    return df\n",
        "\n",
        "customer_data = clean_data(customer_data)\n",
        "survey_data = clean_data(survey_data)\n"
      ],
      "metadata": {
        "id": "6o_kWlOQK67g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "user_item_matrix = customer_data.pivot(index='user_id', columns='item_id', values='purchase_count')\n",
        "\n",
        "# Impute missing values with 0 (or any other suitable strategy)\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
        "user_item_matrix_imputed = imputer.fit_transform(user_item_matrix)\n",
        "\n",
        "model = NMF(n_components=10)\n",
        "user_features = model.fit_transform(user_item_matrix_imputed)  # Use the imputed matrix\n",
        "item_features = model.components_\n"
      ],
      "metadata": {
        "id": "sLyaQp1UK8jp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "customer_data = pd.read_csv('customer_data.csv')\n",
        "survey_data = pd.read_csv('survey_data.csv')\n",
        "\n",
        "def clean_data(df):\n",
        "    # Drop rows with missing values in all columns\n",
        "    df.dropna(how='all', inplace=True)\n",
        "    # Additional cleaning steps\n",
        "    return df\n",
        "\n",
        "customer_data = clean_data(customer_data)\n",
        "survey_data = clean_data(survey_data)\n",
        "\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "user_item_matrix = customer_data.pivot(index='user_id', columns='item_id', values='purchase_count')\n",
        "\n",
        "# Impute missing values with 0\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
        "user_item_matrix_imputed = imputer.fit_transform(user_item_matrix)\n",
        "\n",
        "model = NMF(n_components=10)\n",
        "user_features = model.fit_transform(user_item_matrix_imputed)\n",
        "item_features = model.components_\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "# Check if 'item_description' column exists before proceeding\n",
        "if 'item_description' in customer_data.columns:\n",
        "    item_features = tfidf.fit_transform(customer_data['item_description'])\n",
        "else:\n",
        "    print(\"Warning: 'item_description' column not found in customer_data.\")"
      ],
      "metadata": {
        "id": "byLaNjfxK-wv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "\n",
        "# Initialize the ImageDataGenerator with rescaling\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Update this path to point to your actual training data directory\n",
        "# Make sure this path is correct and the directory contains images\n",
        "train_directory = '/content/drive/My Drive/train'\n",
        "\n",
        "# Create the training data generator\n",
        "train_generator = datagen.flow_from_directory(train_directory,\n",
        "                                              target_size=(150, 150),\n",
        "                                              batch_size=20,\n",
        "                                              class_mode='binary')\n",
        "\n",
        "# Verify if the generator found any images\n",
        "if train_generator.samples == 0:\n",
        "    print(\"Error: No images found in the training directory. Please check the path.\")\n",
        "else:\n",
        "    # Load the VGG16 base model with pre-trained ImageNet weights, excluding the top fully connected layers\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "    # Create a Sequential model and add the base model and custom layers\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model with optimizer, loss function, and metrics\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model using the training data generator\n",
        "    model.fit(train_generator, steps_per_epoch=1, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP3DBR-LYbzG",
        "outputId": "4f2823e2-37e7-4f1d-9c28-261b2124225b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 10 images belonging to 5 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 14s 14s/step - loss: 0.7864 - accuracy: 0.3000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 8s 8s/step - loss: -8.5421 - accuracy: 0.2000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 11s 11s/step - loss: -8178.6382 - accuracy: 0.2000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 9s 9s/step - loss: -501787.5625 - accuracy: 0.2000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 10s 10s/step - loss: -10012078.0000 - accuracy: 0.2000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 11s 11s/step - loss: -119757992.0000 - accuracy: 0.2000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 8s 8s/step - loss: -1020523136.0000 - accuracy: 0.2000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 10s 10s/step - loss: -6769087488.0000 - accuracy: 0.2000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 9s 9s/step - loss: -37323448320.0000 - accuracy: 0.2000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 9s 9s/step - loss: -177915330560.0000 - accuracy: 0.2000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 10s 10s/step - loss: -753716953088.0000 - accuracy: 0.2000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 9s 9s/step - loss: -2890662412288.0000 - accuracy: 0.2000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 8s 8s/step - loss: -10195539329024.0000 - accuracy: 0.2000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 11s 11s/step - loss: -33459345031168.0000 - accuracy: 0.2000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 9s 9s/step - loss: -103165542268928.0000 - accuracy: 0.2000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 10s 10s/step - loss: -300811892555776.0000 - accuracy: 0.2000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 10s 10s/step - loss: -834563416784896.0000 - accuracy: 0.2000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 8s 8s/step - loss: -2214069197078528.0000 - accuracy: 0.2000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 10s 10s/step - loss: -5641177550290944.0000 - accuracy: 0.2000\n",
            "Epoch 20/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU\n",
        "\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Dense(256, input_dim=100))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(28 * 28 * 1, activation='tanh'))\n",
        "    model.add(Reshape((28, 28, 1)))\n",
        "    return model\n",
        "\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "def build_gan(generator, discriminator):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "discriminator.trainable = False\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Training the GAN\n",
        "import numpy as np\n",
        "\n",
        "def train_gan(gan, generator, discriminator, epochs, batch_size):\n",
        "    for epoch in range(epochs):\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "        generated_images = generator.predict(noise)\n",
        "        real_images = np.random.random((batch_size, 28, 28, 1))\n",
        "\n",
        "        labels_real = np.ones((batch_size, 1))\n",
        "        labels_fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_images, labels_real)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "        valid_y = np.array([1] * batch_size)\n",
        "        g_loss = gan.train_on_batch(noise, valid_y)\n",
        "\n",
        "        print(f\"Epoch: {epoch} [D loss: {d_loss[0]}] [G loss: {g_loss}]\")\n",
        "\n",
        "train_gan(gan, generator, discriminator, epochs=10000, batch_size=32)\n"
      ],
      "metadata": {
        "id": "4WuzV8DW5ZoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80546beb-106f-45f5-a80d-ed36245b7bea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 0 [D loss: 0.7820447087287903] [G loss: 0.8909270763397217]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'customer_data.csv' exists and contains relevant data\n",
        "customer_data = pd.read_csv('customer_data.csv')\n",
        "\n",
        "# ... (Rest of your data loading and cleaning code) ...\n",
        "\n",
        "user_item_matrix = customer_data.pivot(index='user_id', columns='item_id', values='purchase_count')\n",
        "\n",
        "# Impute missing values with 0\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
        "user_item_matrix_imputed = imputer.fit_transform(user_item_matrix)\n",
        "\n",
        "model = NMF(n_components=10)\n",
        "user_features = model.fit_transform(user_item_matrix_imputed)  # Assign the result to user_features\n",
        "item_features = model.components_\n",
        "\n",
        "# ... (Rest of your code, including hybrid_recommendations function) ...\n",
        "\n",
        "recommendations = hybrid_recommendations(user_id=1, user_features=user_features, item_features=item_features)\n",
        "print(recommendations)"
      ],
      "metadata": {
        "id": "LXPRlnyKLD1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests Pillow\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "import io\n",
        "import pandas as pd\n",
        "from IPython.display import display # Used to display images\n",
        "\n",
        "def fetch_pinterest_data(api_url, params, headers):\n",
        "    response = requests.get(api_url, params=params, headers=headers)\n",
        "    return response.json()\n",
        "\n",
        "# Note: Replace with a valid Pinterest API token for actual data fetching\n",
        "api_url = \"https://api.pinterest.com/v1/me/pins/\"\n",
        "params = {\"fields\": \"id,link,note,creator,board,created_at\"}\n",
        "headers = {\"Authorization\": \"Bearer YOUR_ACCESS_TOKEN\"}\n",
        "# pinterest_data = fetch_pinterest_data(api_url, params, headers)\n",
        "\n",
        "# Sample pinterest data\n",
        "pinterest_data = pd.DataFrame({\n",
        "    'id': [301, 302, 303, 304, 305],\n",
        "    'link': ['https://i.pinimg.com/564x/f8/05/92/f80592cbd4dbfa3185b6899d2aa79889.jpg',\n",
        "             'https://i.pinimg.com/736x/9a/80/b9/9a80b99bfbbf15cbf2fdfe186696a315.jpg',\n",
        "             'https://i.pinimg.com/564x/6b/ea/e2/6beae29e16d27cdeebd111ea2def87c5.jpg',\n",
        "             'https://i.pinimg.com/564x/6f/8c/14/6f8c14fb4a9a535153f5db945ab64968.jpg',\n",
        "             'https://i.pinimg.com/564x/27/b6/91/27b69120f62154b3beebc1aa9b2cf9b3.jpg'], # Replace with actual image URLs\n",
        "    'note': ['Style 1', 'Style 2', 'Style 3', 'Style 4', 'Style 5'],\n",
        "    'creator': ['User1', 'User2', 'User3', 'User4', 'User5'],\n",
        "    'board': ['Board1', 'Board2', 'Board3', 'Board4', 'Board5'],\n",
        "    'created_at': ['2023-06-15', '2023-06-16', '2023-06-17', '2023-06-18', '2023-06-19']\n",
        "})\n",
        "\n",
        "def process_image(url):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(io.BytesIO(response.content))\n",
        "    img = img.resize((150, 150))\n",
        "    return img\n",
        "\n",
        "# Example of integrating Pinterest data with existing models\n",
        "def integrate_pinterest_data(pinterest_data, existing_data):\n",
        "    combined_data = existing_data.append(pinterest_data, ignore_index=True)\n",
        "    return combined_data\n",
        "\n",
        "# combined_data = integrate_pinterest_data(pinterest_data, existing_data)\n",
        "\n",
        "def recommend_similar_products(pinterest_pin):\n",
        "    img = process_image(pinterest_pin['link'])\n",
        "    # Use the hybrid recommendation engine to find similar products\n",
        "    # Note: This part assumes you have a working hybrid_recommendations function and relevant data\n",
        "    # recommendations = hybrid_recommendations(user_id=1, user_features=user_features, item_features=item_features)\n",
        "    # For demonstration, let's just display the image\n",
        "    display(img)\n",
        "    return # Replace with actual recommendations\n",
        "\n",
        "# Example pin\n",
        "pin = pinterest_data.iloc[0]\n",
        "recommend_similar_products(pin) # Call the function to process and display the image\n",
        "# print(\"Recommendations based on Pinterest pin:\", recommendations) # Uncomment when you have actual recommendations"
      ],
      "metadata": {
        "id": "G2gmcUC362x9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}